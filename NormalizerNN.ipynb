{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PghXhda5wIVU"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "!pip install albumentations\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k9KFngxEwXKj"
   },
   "outputs": [],
   "source": [
    "!unzip \"/content/drive/MyDrive/archive (1).zip\" -d \"/content/data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zNNVy8GBwdva"
   },
   "source": [
    "# 1. Исследую данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tQ4TAGhxwaRX"
   },
   "outputs": [],
   "source": [
    "train_path = '/content/data/training_frames_keypoints.csv'\n",
    "test_path = '/content/data/test_frames_keypoints.csv'\n",
    "\n",
    "train = pd.read_csv(train_path)\n",
    "test = pd.read_csv(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "exz9KB5_w689"
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dL6Ox9l6w93I"
   },
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VmVC7qGqw_XO"
   },
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b6WtnKozxEr6"
   },
   "outputs": [],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1cjbmLoTzIMb"
   },
   "source": [
    "# 2. Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Llmv9PoYzJ4_"
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    'batch_size'    : 64,\n",
    "    'num_workers'   : 0,\n",
    "    'total_epochs'  : 201,\n",
    "    'save_epoch'    : 10,\n",
    "    'learning_rate' : 0.001,\n",
    "    'train_path'    : '/content/data/training',\n",
    "    'test_path'     : '/content/data/test',\n",
    "    'save_path'     : './weights',\n",
    "    'input_size'    : 100,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LsNdFL9txLBV"
   },
   "source": [
    "# 3. Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fvrbUmtqxFif"
   },
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, images_path, image_names, landmarks, transform=None):\n",
    "        super().__init__()\n",
    "        self.images_path = images_path\n",
    "        self.image_names = image_names\n",
    "        self.landmarks = landmarks\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_names)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Путь к изображению\n",
    "        img_name = self.image_names[index]\n",
    "        img_path = self.images_path + '/' + img_name\n",
    "\n",
    "        img = cv2.imread(img_path)\n",
    "\n",
    "        landmarks_img = np.array(self.landmarks.iloc[index])\n",
    "        landmarks_img = landmarks_img.reshape(-1, 2)\n",
    "\n",
    "        if self.transform:\n",
    "            transformed = self.transform(image=img, keypoints=landmarks_img)\n",
    "\n",
    "            img = transformed[\"image\"]\n",
    "\n",
    "            landmarks_img = transformed[\"keypoints\"]\n",
    "            landmarks_img = np.array(landmarks_img).flatten()\n",
    "\n",
    "        return img, landmarks_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "99N-bKONxcWz"
   },
   "outputs": [],
   "source": [
    "train_image_names = train['Unnamed: 0']\n",
    "train_landmarks = train.drop('Unnamed: 0', axis=1)\n",
    "test_image_names = test['Unnamed: 0']\n",
    "test_landmarks = test.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dJdEFRFWx78X"
   },
   "outputs": [],
   "source": [
    "train_transform = A.Compose([\n",
    "    A.Resize(220, 220),\n",
    "    ToTensorV2()\n",
    "], keypoint_params=A.KeypointParams(format='xy', remove_invisible=False))\n",
    "\n",
    "test_transform = A.Compose([\n",
    "    A.Resize(220, 220),\n",
    "    ToTensorV2()\n",
    "], keypoint_params=A.KeypointParams(format='xy', remove_invisible=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zcK0kfL6yBpk"
   },
   "outputs": [],
   "source": [
    "train_data = MyDataset(\n",
    "    config['train_path'],\n",
    "    train_image_names,\n",
    "    train_landmarks,\n",
    "    train_transform\n",
    "    )\n",
    "\n",
    "test_data = MyDataset(\n",
    "    config['test_path'],\n",
    "    test_image_names,\n",
    "    test_landmarks,\n",
    "    test_transform\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pNRJrN0S2w6i"
   },
   "outputs": [],
   "source": [
    "l = train_data[0][1]\n",
    "l = np.array(l)\n",
    "\n",
    "x = l[::2]\n",
    "y = l[1::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "711IrNAvLu6X"
   },
   "outputs": [],
   "source": [
    "train_data[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lM8Tr2mY1Ipc"
   },
   "outputs": [],
   "source": [
    "plt.scatter(x, y, s=5)\n",
    "plt.imshow(train_data[0][0][0], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rz74xWcQ6HcI"
   },
   "source": [
    "# 4. DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NpRqdWHK1KBr"
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=config['batch_size'],\n",
    "    shuffle=True,\n",
    "    num_workers=config['num_workers'],\n",
    "    drop_last=True,\n",
    "    pin_memory=True\n",
    "    )\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_data,\n",
    "    batch_size=config['batch_size'],\n",
    "    shuffle=False,\n",
    "    num_workers=config['num_workers'],\n",
    "    pin_memory=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4JNZGz4R67a_"
   },
   "source": [
    "# 5. Архитектура: train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "idpJKfCT6z1L"
   },
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, criterion, optimizer):\n",
    "    losses = np.array([])\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for img, landmarks in train_loader:\n",
    "        img, landmarks = img.to(device), landmarks.to(device)\n",
    "        img = img.float()\n",
    "        landmarks = landmarks.float()\n",
    "\n",
    "        output = model(img)\n",
    "        loss = criterion(output, landmarks)\n",
    "\n",
    "        losses = np.append(losses, loss.item())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return losses.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aGY_tl62M4yk"
   },
   "outputs": [],
   "source": [
    "def test(model, device, test_loader, criterion):\n",
    "    losses = np.array([])\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for img, landmarks in test_loader:\n",
    "            img, landmarks = img.to(device), landmarks.to(device)\n",
    "            img = img.float()\n",
    "            landmarks = landmarks.float()\n",
    "\n",
    "            output = model(img)\n",
    "            loss = criterion(output, landmarks)\n",
    "\n",
    "            losses = np.append(losses, loss.item())\n",
    "\n",
    "    return losses.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xLcqnMN0NFFm"
   },
   "source": [
    "# 6. Модель, оптимизатор и функция потерь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "id": "eJ3Q7Z4CM_nk"
   },
   "outputs": [],
   "source": [
    "class SimpleCNNModel(nn.Module) :\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = resnet50(pretrained=True)\n",
    "        self.model.fc = nn.Linear(2048, 68*2)\n",
    "\n",
    "    def forward(self, x) :\n",
    "        output = self.model(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RAbHmx97N533"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "\n",
    "print('Device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ifSlXEseNfFA"
   },
   "outputs": [],
   "source": [
    "model = SimpleCNNModel().to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config['learning_rate'])\n",
    "criterion = nn.SmoothL1Loss().to(device)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=5, eta_min=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zvSyhlSdOA37"
   },
   "source": [
    "# 7. Обучение!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-OIeUa5aObQx"
   },
   "outputs": [],
   "source": [
    "def save_checkpoint(save_path, state, epoch, tag=''):\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "\n",
    "    filename = os.path.join(save_path, \"{}checkpoint-{:06}.pth.tar\".format(tag, epoch))\n",
    "    torch.save(state, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QD6izFcwOcK6"
   },
   "outputs": [],
   "source": [
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f7b_oiTZOeV2"
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ehRzd-yaN9l0"
   },
   "outputs": [],
   "source": [
    "print('Начало обучения!!!')\n",
    "log = {\"epoch\": [], \"train_loss\": [],  \"val_loss\": []}\n",
    "\n",
    "for epoch in range(config['total_epochs']):\n",
    "    train_loss = train(model, device, train_loader, criterion, optimizer)\n",
    "    test_loss = test(model, device, test_loader, criterion)\n",
    "\n",
    "    if epoch % config['save_epoch'] == 0:\n",
    "        state = {\n",
    "            'epoch': epoch,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'loss': test_loss,\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'criterion': criterion.state_dict()\n",
    "        }\n",
    "        save_checkpoint(config['save_path'], state, epoch, '')\n",
    "\n",
    "    log['epoch'].append(epoch)\n",
    "    log['train_loss'].append(train_loss)\n",
    "    log['val_loss'].append(test_loss)\n",
    "\n",
    "    clear_output(wait=True)\n",
    "    plt.plot(log['epoch'], log['train_loss'], label='train')\n",
    "    plt.plot(log['epoch'], log['val_loss'], label='val')\n",
    "    plt.legend()\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    plt.title('Loss')\n",
    "    plt.show()\n",
    "\n",
    "    line = '[{}/{}]\\t\\tLR: {:.2}\\t\\tTrain loss: {:.3}\\t\\tVal loss: {:.3}'.format(\n",
    "        epoch,\n",
    "        config['total_epochs'] - 1,\n",
    "        get_lr(optimizer),\n",
    "        train_loss,\n",
    "        test_loss\n",
    "    )\n",
    "\n",
    "    print(line)\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "print('КОНЕЦ!!! НАКОНЕЦ!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dHjvnhW9s2FE"
   },
   "outputs": [],
   "source": [
    "model.cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rt-RjDlsZ51t"
   },
   "source": [
    "# 8. Проверка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "id": "SoR6HVgjPouD"
   },
   "outputs": [],
   "source": [
    "def show_img_with_landmarks(img, landmarks, predict):\n",
    "    x = landmarks[::2]\n",
    "    y = landmarks[1::2]\n",
    "\n",
    "    x_pred = predict.detach().numpy()[0, ::2]\n",
    "    y_pred = predict.detach().numpy()[0, 1::2]\n",
    "\n",
    "    size = 10\n",
    "    color = '#00ff5f'\n",
    "    color_pred = '#ec5353'\n",
    "\n",
    "    plt.scatter(x, y, s=size, c=color)\n",
    "    plt.scatter(x_pred, y_pred, s=size, c=color_pred)\n",
    "    plt.imshow(img[0][0], cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XAJnPkg6wTW_"
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('/content/drive/MyDrive/checkpoint-000050.pth.tar', map_location=torch.device('cpu'))['state_dict'])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NvWKa5GmcRZb"
   },
   "outputs": [],
   "source": [
    "index = 1\n",
    "\n",
    "test_img = torch.tensor(np.expand_dims(train_data[index][0], axis=0)).float()\n",
    "test_l = train_data[index][1]\n",
    "pred_l = model(test_img)\n",
    "\n",
    "show_img_with_landmarks(test_img, test_l, pred_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mup2FzG2N36p"
   },
   "outputs": [],
   "source": [
    "test_img.shape"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
